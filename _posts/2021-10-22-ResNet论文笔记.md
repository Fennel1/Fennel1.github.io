---
layout:     post
title:      ResNet论文笔记
subtitle:   Deep Residual Learning for Image Recognition
date:       2021-10-22
author:     fennel
header-img: /my_img/resnest50.jpg
catalog: true
tags:
    - 论文笔记
---

## 论文pdf

- [Deep Residual Learning for Image Recognition](/paper/resnet.pdf)

## 前言

![resnetf1](/my_img/resnetf1.png)

**Purpose：** 更深层的神经网络往往更加难以训练，而且堆叠更多的层会带来更多的问题，如梯度爆炸、梯度消失、网络退化(degradation)等。梯度爆炸、消失问题可以通过BN层与参数初始化来解决；但网络退化问题则没有很好的办法去解决。退化是指随着网络深度的增加，网络层数饱和，导致优化困难。而且训练误差与测试误差随着网络加深反而更大了，这种误差更大并不是由过拟合引起的。 <br>
**Method：** 作者通过一种残差结构，将输入的特征经过恒等映射输出出去来解决网络退化问题。实验结果表明残差网络更容易优化，可以通过训练更深的网络来获得更高的准确性。 <br>
**Results：** 使用了残差结构块的模型深度达到了152层(深度为VGG的8倍，但仍有更低的复杂度)，并在ImageNet测试集上达到了3.57%的top-5错误率，取得了ILSVRC 2015分类任务的第一名。还在ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation的任务中均取得了第一名。<br>

![ImageNet图像识别挑战赛](/my_img/imagenet.png)

从resnet开始图像的分类任务已经做到比人还准确了，所以后面ImageNet图像分类比赛也没再举行了。

## 残差结构设计思路

#### 残差表示(Residual Representations)

- VLAD是一种残差向量的字典编码表示，而Fisher Vector是VLAD的概率表示方法。它们都用于图像检索和分类的浅层表示，对于它们来说编码残差矢量比编码原始向量更有效
- 在计算机图形学中通常使用多重网格方法(Multigrid method)求解微分方程(PDE)，但可以用依赖于残差向量的分层预处理来替代多重网格方法。有研究表明，使用残差向量更好优化、收敛速度更快

#### 跨层连接(Shortcut Connections)

- 训练多层感知机时，在输入与输出之间加一层线性层
- GoogLeNet中中间层连接辅助分类器来解决梯度爆炸、消失
- Inception与highway也都用到了跨层连接

## 残差结构

![resnetf2](/my_img/resnetf2.png)

x为输入，H(x)为是我们想提取到的特征也就是输出。假设可以通过多个非线性层来逼近这个输出 H(x) 的话，同理它也可以逼近 H(x)-x 。那与其让网络学习去近似 H(x) 不如让网络去近似一个残差函数 F(x)=H(x)-x 。虽然这两种方式都能逼近我们要的输出，但网络学习的难易程度不同。<br>

![F1](https://latex.codecogs.com/svg.image?y=F(x,\left\{W_i&space;\right\})&plus;x)
![F2](https://latex.codecogs.com/svg.image?y=F(x,\left\{W_i&space;\right\})&plus;W_sx)

## Architecture

## 实验细节
