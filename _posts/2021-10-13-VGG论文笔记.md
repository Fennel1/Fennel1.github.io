---
layout:     post
title:      VGG论文笔记
subtitle:   VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION
date:       2021-10-13
author:     fennel
header-img: /my_img/resnest50.jpg
catalog: false
tags:
    - 论文笔记
---

## 论文pdf
- [VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION](/paper/VGG.pdf)

## 前言

![vggILSVRC2014](/my_img/vggILSVRC2014.png)

VGG的模型与传统的CNN模型没有太大的区别，主要对具有33的卷积**滤波器**架构进行了研究，探究深度对模型的影响，
发现将模型加深到16-19层时效率有显著的提高。并获得2014年ImageNet挑战赛图像分类的第二名(第一名为GoogLeNet)。

- 卷积核（kernels）：二维的矩阵
- 滤波器（filters）：多个卷积核组成的三维矩阵，多出的一维是通道(channel)
- 特征图 (feature map) ：卷积层提取到的特征，即多个二维图堆叠在一起即为一个特征图

### Tricks

- 使用小卷积核(主要为3×3，少部分1×1)
- 网络层数更深，通道数更多
- 池化核大小设置为2×2
- 训练深层网络时(16、19层VGG)使用前面模型的参数来进行参数初始化
- 网络测试时将三个全连接层替换为3个卷积层

---

## Architecture

![vggtable1](/my_img/vggtable1.png)
![vggtable3](/my_img/vggtable3.png)

实验共分为六组层数由11层加深到19层(层数仅包括卷积层与全连接层)，通道数由64扩大至512，但因为使用的卷积核均为1×1、3×3的小卷积核，即使网络很深参数量也不会很大。每个卷积层后跟有ReLU激活函数，池化层使用的是大小为2×2，步长为2的最大池化。
曾在ALexNet中使用的局部响应归一化层，该层会对相邻的N个通道在同一像素位置处的像素值进行归一化(normalize)。通过上图比较A与A-LRN发现准确率没有提升，还花费了更多计算资源。所以在接下来的实验中均没有使用LRN层。<br>

VGG中只使用了1×1、3×3的卷积核，使用小卷积核的理由是两个3×3的卷积堆叠与一个5×5的卷积获得的感受野大小相同，同理三个3×3的卷积堆叠与一个7×7的卷积获得的感受野大小相同。此外堆叠多个小卷积核替代大卷积核还有如下优势：

- 由一个激活函数增加到三个，使决策函数更具有判别能力。
- 卷积层滤波器参数减少，三层3×3卷积核的参数个数为3×(C×C×3×3)=27C^2，一层7×7卷积核的参数个数为C×C×7×7=49C^2。还使用1×1的卷积核对输入通道数进行线性变换，1×1卷积核可以在不影响感受野的情况下增加非线性判别(跟在卷积层后的激活函数)。
- 小卷积核替代大卷积核有正则化的作用，堆叠的小卷积核是将大卷积核提取到的特征进行了分解。

### Feture map 变化

| 层数 | 大小 | 通道数 |
| :---: | :---: | :---: |
| 1 | 224×224 | 3 |
| 2 | 112×112 | 64 |
| 3 | 56×56 | 128 |
| 4 | 28×28 | 256 |
| 5 | 14×14 | 512 |
| 6 | 7×7 | 512 |

随着特征图由一开始的224×224×3到最后的7×7×512，通过卷积、池化操作将特征从图片的相对位置分摊到channel上，再通过全连接层将特征压缩为稠密的feature map，最后给到softmax进行分类。 

---

## 训练(TRAINING)

---

## 测试(TESTING)

---

## 分类试验

### 单尺度评估

### 多尺度评估

### 多crop评估

---

## 多模型融合
