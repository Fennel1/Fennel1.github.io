---
layout:     post
title:      图神经网络综述阅读笔记
subtitle:   A Comprehensive Survey on Graph Neural Networks
date:       2021-11-20
author:     fennel
header-img: /my_img/resnest50.jpg
catalog: true
tags:
    - 论文笔记
    - 深度学习
---

## 前言

曾经在机器学习的特征工程中主要依靠人工提取特征，而现在通过端到端的深度学习框架(CNN、RNN、自编码器)可以更好的进行特征提取。深度学习的快速发展得益于计算机算力的大幅度提升、大规模的训练数据以及
可以有效的从欧式数据中提取潜在特征。虽然深度学习可以有效地应用于欧式数据，但越来越多的数据是以图的形式来表示，如：化学分子结构、论文的引文系统。图中有大小可变的无序节点，每个节点的邻居数目可能
不同，导致卷积操作难以应用于图数据。且图中每个节点不再独立，节点之间通过各种类型的连接与其他节点相关。为了处理这种不规则的图数据，有了许多图数据深度学习方法的研究。现将这些图神经网络分为四类：
**图循环神经网络**、**图卷积神经网络**、**图自编码器**、**时空图神经网络**。<br>

---

## 研究背景

最早的图神经网络应用是1997年由Sperduti将神经网络应用于无环图，而图神经网络的概念在2005年由Gori提出。早期的研究都属于图循环神经网络，通过迭代传播邻居信息的方式来更新节点直至到达稳定，
但计算量过大导致训练十分昂贵。后由于CNN在计算机视觉领域的成功，出现了大量图卷积的概念。图卷积神经网络主要分为两类，一类基于谱方法，一类基于空间方法。

#### GNN vs network embedding(网络嵌入表达)

network embedding旨在将网络中的节点表示为低维向量，同时保留网络拓扑结构信息与节点信息，以便使用现成工具即可轻松完成后续的图分析任务。其与GNN的主要区别在于GNN是一组为各种任务设计的
神经网络模型，而network embedding涵盖了针对同一任务的各种方法，且network embedding中还包含了非深度学习的方法。

#### GNN vs graph kernel methods(图核方法)

graph kernel methods主要用于图分类问题，通过核函数来测量图之间的相似性，再通过支持向量机进行图监督学习。图核方法也是通过映射函数将图或节点压缩为向量，但不同于GNN图核方法的映射函数是确定的。

